_target_: src.policy.JointPolicyVPG

# Define below the constructor kwargs
portfolio_model:
  _target_: regelum.model.PerceptronWithTruncatedNormalNoise
  dim_input: = ${common.number_of_stocks} * 2 + 2
  dim_output: $ common.number_of_stocks
  dim_hidden: 100
  n_hidden_layers: 4
  hidden_activation: 
    _target_: torch.nn.Tanh
  output_bounds: $ common.action_bounds_left
  is_truncated_to_output_bounds: True
  output_activation: 
    _target_: regelum.model.MultiplyByConstant
    constant: 0.1
  stds: = [0.05]*(${common.number_of_stocks})
market_model:
  _target_: regelum.model.PerceptronWithTruncatedNormalNoise
  dim_input: = ${common.number_of_stocks} * 2 + 2
  dim_output: =  ${common.number_of_stocks} * ( ${common.number_of_stocks} + 3 ) // 2
  dim_hidden: 100
  n_hidden_layers: 4
  hidden_activation: 
    _target_: torch.nn.Tanh
  output_bounds: $ common.action_bounds_right
  is_truncated_to_output_bounds: True
  output_activation: 
    _target_: regelum.model.MultiplyByConstant
    constant: 0.1
  stds: = [0.05]*( ${common.number_of_stocks} * ( ${common.number_of_stocks} + 3 ) // 2 )
portfolio_critic: ~ portfolio_critic
market_critic: ~ market_critic
system: ~ system
is_normalize_advantages: True
gae_lambda: 0.95
N_episodes: 16
sampling_time: $ common.sampling_time
type_of_adversary: fixed
fixed_market_actions: = regelum.utils.rg.array([-0.1, 0.0, 0.1, 0.1, 0.2, 0.3] + [0.1]*(${common.number_of_stocks} * ( ${common.number_of_stocks} -1 ) // 2)).reshape(1, -1)
pretrain: True